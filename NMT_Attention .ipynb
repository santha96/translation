{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUnfV9hCPFYN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdXdJE7LbCbZ",
        "outputId": "1af945b7-6c2f-4c8c-89d4-ae2eb3567139"
      },
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Ed_TzhbI--"
      },
      "source": [
        "en = spacy.load(\"en_core_web_sm\")\n",
        "de=spacy.load(\"de_core_news_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e_x3nZaaXK8"
      },
      "source": [
        "seed=1234\n",
        "\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(1234)\n",
        "torch.backends.cudnn.determininistic=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAk5vwMdaxSG"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=\"cuda\"\n",
        "else:\n",
        "  device=\"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7N6j3H4ua-Yp",
        "outputId": "55e03c46-06bc-470a-abfb-e7731fd06a43"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JIOrgfla_Pu"
      },
      "source": [
        "def tokenize_de(text):\n",
        "  return [tok.text for tok in de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "  return [tok.text for tok in en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y87QBd7-bkSQ"
      },
      "source": [
        "source=data.Field(init_token=\"<sos>\",eos_token=\"<eos>\",tokenize=tokenize_de,lower=True)\n",
        "target=data.Field(init_token=\"<sos>\",eos_token=\"<eos>\",tokenize=tokenize_en,lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_2pyaRCb0o8",
        "outputId": "a776f37d-75e6-4152-86ec-e5b8fc9b8548"
      },
      "source": [
        "train_data,valid_data,test_data=datasets.Multi30k.splits(exts=(\".de\",\".en\"),fields=(source,target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 480kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 92.2kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 86.9kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOBtXOf0cNwI"
      },
      "source": [
        "source.build_vocab(train_data,min_freq=2)\n",
        "target.build_vocab(train_data,min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20pi1JvpD9b9"
      },
      "source": [
        "train_iterator,valid_iterator,test_iterator=data.BucketIterator.splits((train_data,valid_data,test_data),batch_size=64,device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqOwOgQciF2"
      },
      "source": [
        "batch=next(iter(train_iterator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqCCNMEXcnEX",
        "outputId": "7217450e-f60b-4728-ed0c-3a35a56b7f0b"
      },
      "source": [
        "batch.src.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwYmp9QVL1rz"
      },
      "source": [
        "class encoder(nn.Module):\n",
        "  def __init__(self,input_dim,embed_dim,hidden_dim,dropout):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.embed_dim = embed_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding = nn.Embedding(input_dim,embedding_dim)\n",
        "    self.rnn = nn.GRU(embedding_dim,hidden_dim,bidirectional=True)\n",
        "    self.lin1 = nn.Linear(hidden_dim*2,hidden_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self,input):\n",
        "    embed = self.dropout(self.embedding(input))\n",
        "    output,hidden=self.rnn(embed)\n",
        "    hidden=torch.tanh(self.lin1(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1)))\n",
        "    return output,hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k8HRdN5L7Ib"
      },
      "source": [
        "class attention(nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.attention = nn.Linear((hidden_dim*2)+hidden_dim,hidden_dim)\n",
        "    self.v = nn.Linear(hidden_dim,1,bias=False)\n",
        "  \n",
        "  def forward(self,hidden,encoder_output):\n",
        "    batch_size = encoder_output.shape[1]\n",
        "    src_len = encoder_output.shape[0]\n",
        "    hidden=hidden.unsqueeze(1).repeat(1,src_len,1)\n",
        "    encoder_output=encoder_output.permute(1,0,2)\n",
        "    energy = torch.tanh(self.attention(torch.cat((hidden, encoder_output), dim = 2))) \n",
        "    attention = self.v(energy).squeeze(2)\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUQ1rTsFL9N-"
      },
      "source": [
        "class decoder(nn.Module):\n",
        "  def __init__(self,output_dim,embedding_dim,hidden_dim,dropout,attn):\n",
        "    super().__init__()\n",
        "    self.output_dim = output_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.attn=attn\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed = nn.Embedding(output_dim,embedding_dim)\n",
        "    self.rnn = nn.GRU(hidden_dim*2+embedding_dim,hidden_dim)\n",
        "    self.fc=nn.Linear(hidden_dim*2+embedding_dim+hidden_dim,output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,input,hidden,encoder_output):\n",
        "    input = input.unsqueeze(0)\n",
        "    embed =self.dropout(self.embed(input))\n",
        "    a=self.attn(hidden,encoder_output)\n",
        "    a=a.unsqueeze(1)\n",
        "    encoder_output = encoder_output.permute(1,0,2)\n",
        "    weighted= torch.bmm(a,encoder_output)\n",
        "    weighted = weighted.permute(1,0,2)\n",
        "    rnn_input = torch.cat((embed,weighted),dim=2)\n",
        "    output,hidden = self.rnn(rnn_input,hidden.unsqueeze(0))\n",
        "    assert (output == hidden).all()\n",
        "        \n",
        "    embed = embed.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "        \n",
        "    prediction = self.fc(torch.cat((output, weighted, embed), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "    return prediction, hidden.squeeze(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8OiqHZrL_DY"
      },
      "source": [
        "class seq2seq(nn.Module):\n",
        "  def __init__(self,encoder,decoder,device):\n",
        "    super().__init__()\n",
        "    self.encoder=encoder\n",
        "    self.decoder=decoder\n",
        "    self.device=device\n",
        "  \n",
        "  def forward(self,src,trg,teacher_forcing_ratio=0.5):\n",
        "    trg_len=trg.shape[0]\n",
        "    batch_size = trg.shape[1]\n",
        "    output_dim=self.decoder.output_dim\n",
        "    outputs=torch.zeros(trg_len,batch_size,output_dim).to(self.device)\n",
        "    encoder_output,hidden = self.encoder(src)\n",
        "    input=trg[0,:]\n",
        "\n",
        "    for t in range(1,trg_len):\n",
        "      output,hidden=self.decoder(input,hidden,encoder_output)\n",
        "      outputs[t]=output\n",
        "      top=output.argmax(1)\n",
        "      next_word = random.random() < teacher_forcing_ratio\n",
        "      if next_word:\n",
        "        input = trg[t]\n",
        "      else:\n",
        "        input=top\n",
        "    return outputs      \n",
        "            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJQmrp7iT6gu"
      },
      "source": [
        "input_dim = len(source.vocab)\n",
        "output_dim = len(target.vocab)\n",
        "embedding_dim = 256\n",
        "hidden_dim =512\n",
        "dropout = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4arfB2UFPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a324cc18-11dc-4c53-b083-fdb2bb241cb7"
      },
      "source": [
        "input_dim,output_dim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7855, 5893)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M6-_GXPc0i4"
      },
      "source": [
        "enc=encoder(input_dim,embedding_dim,hidden_dim,dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RHa_17ZdG3L",
        "outputId": "65b0d8cb-f945-47ca-f101-105e2e5f228e"
      },
      "source": [
        "enc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "encoder(\n",
              "  (embedding): Embedding(7855, 256)\n",
              "  (rnn): GRU(256, 512, bidirectional=True)\n",
              "  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6VN3hgHdLPC"
      },
      "source": [
        "attn=attention(hidden_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNgzfvTadUGk",
        "outputId": "a9d80bbc-80b6-43a1-b8ed-e7127de63fba"
      },
      "source": [
        "attn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "attention(\n",
              "  (attention): Linear(in_features=1536, out_features=512, bias=True)\n",
              "  (v): Linear(in_features=512, out_features=1, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aik5GsjdXEw"
      },
      "source": [
        "dec=decoder(output_dim,embedding_dim,hidden_dim,dropout,attn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27I8NA6DdgqB",
        "outputId": "61406ddc-037c-455c-fd7c-3a8515240e2e"
      },
      "source": [
        "dec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "decoder(\n",
              "  (attn): attention(\n",
              "    (attention): Linear(in_features=1536, out_features=512, bias=True)\n",
              "    (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "  )\n",
              "  (embed): Embedding(5893, 256)\n",
              "  (rnn): GRU(1280, 512)\n",
              "  (fc): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMOk-yH2djZI"
      },
      "source": [
        "model=seq2seq(enc,dec,device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4IO2pYNdrk1",
        "outputId": "5e4e7cd7-dc2c-4834-b4df-c439abc8f7e2"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "seq2seq(\n",
              "  (encoder): encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): decoder(\n",
              "    (attn): attention(\n",
              "      (attention): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embed): Embedding(5893, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBu36pq4eFEL",
        "outputId": "adfc322c-d362-440a-fd36-6f74e0267cd1"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "seq2seq(\n",
              "  (encoder): encoder(\n",
              "    (embedding): Embedding(7855, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (lin1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): decoder(\n",
              "    (attn): attention(\n",
              "      (attention): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embed): Embedding(5893, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMW_6Lffc3d",
        "outputId": "049b5a20-e47b-45cc-8739-cc67f8f359d2"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 20,518,917 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NjeVfcFfl9y"
      },
      "source": [
        "optim = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTdz8c70fpJV"
      },
      "source": [
        "TRG_PAD_IDX = target.vocab.stoi[target.pad_token]\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf6EbCiAW64A"
      },
      "source": [
        "def train(model,iterator,optim,loss_fn,clip):\n",
        "  model.train()\n",
        "  epoch_loss=0\n",
        "  for i,batch in enumerate(iterator):\n",
        "    src=batch.src\n",
        "    trg=batch.trg\n",
        "    optim.zero_grad()\n",
        "    pred=model(src,trg)\n",
        "  #  print(pred.shape)\n",
        "    pred_dim=pred.shape[-1]\n",
        "  #  print(pred_dim)\n",
        "    trg=trg[1:].view(-1)\n",
        "   # print(trg.shape)\n",
        "    pred = pred[1:].view(-1, pred_dim)\n",
        "   # print(pred.shape)\n",
        "    loss=loss_fn(pred,trg)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optim.step()\n",
        "    epoch_loss+=loss.item()\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5oHEDv5XLIF"
      },
      "source": [
        "def evaluate(model,iterator,loss_fn):\n",
        "  model.eval()\n",
        "  epoch_loss=0\n",
        "  with torch.no_grad():\n",
        "    for i,batch in enumerate(iterator):\n",
        "      src=batch.src\n",
        "      trg=batch.trg\n",
        "      pred=model(src,trg,0)\n",
        "      pred_dim=pred.shape[-1]\n",
        "      trg=trg[1:].view(-1)\n",
        "      pred = pred[1:].view(-1, pred_dim)\n",
        "      loss=loss_fn(pred,trg)\n",
        "      epoch_loss+=loss.item()\n",
        "  return epoch_loss/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0_O6K0BXP-2"
      },
      "source": [
        "import time\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaemhckYXUGu"
      },
      "source": [
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEnr7WOEXUQ8",
        "outputId": "8f341f94-0c80-49ec-8670-1f1d1e0172e7"
      },
      "source": [
        "epochs=10\n",
        "clip=1\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(0,epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss = train(model,train_iterator,optim,loss_fn,clip)\n",
        "  valid_loss=evaluate(model,valid_iterator,loss_fn)\n",
        "  end_time =time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'getoen-model.pt')\n",
        "    \n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 3m 3s\n",
            "\tTrain Loss: 4.630 | Train PPL: 102.529\n",
            "\t Val. Loss: 4.383 |  Val. PPL:  80.069\n",
            "Epoch: 02 | Time: 3m 3s\n",
            "\tTrain Loss: 3.411 | Train PPL:  30.309\n",
            "\t Val. Loss: 3.547 |  Val. PPL:  34.703\n",
            "Epoch: 03 | Time: 3m 1s\n",
            "\tTrain Loss: 2.723 | Train PPL:  15.229\n",
            "\t Val. Loss: 3.239 |  Val. PPL:  25.506\n",
            "Epoch: 04 | Time: 3m 4s\n",
            "\tTrain Loss: 2.321 | Train PPL:  10.181\n",
            "\t Val. Loss: 3.176 |  Val. PPL:  23.950\n",
            "Epoch: 05 | Time: 3m 4s\n",
            "\tTrain Loss: 1.998 | Train PPL:   7.373\n",
            "\t Val. Loss: 3.128 |  Val. PPL:  22.832\n",
            "Epoch: 06 | Time: 3m 1s\n",
            "\tTrain Loss: 1.768 | Train PPL:   5.858\n",
            "\t Val. Loss: 3.137 |  Val. PPL:  23.039\n",
            "Epoch: 07 | Time: 3m 2s\n",
            "\tTrain Loss: 1.585 | Train PPL:   4.881\n",
            "\t Val. Loss: 3.224 |  Val. PPL:  25.132\n",
            "Epoch: 08 | Time: 3m 0s\n",
            "\tTrain Loss: 1.443 | Train PPL:   4.232\n",
            "\t Val. Loss: 3.337 |  Val. PPL:  28.148\n",
            "Epoch: 09 | Time: 3m 0s\n",
            "\tTrain Loss: 1.330 | Train PPL:   3.783\n",
            "\t Val. Loss: 3.379 |  Val. PPL:  29.334\n",
            "Epoch: 10 | Time: 3m 0s\n",
            "\tTrain Loss: 1.213 | Train PPL:   3.364\n",
            "\t Val. Loss: 3.494 |  Val. PPL:  32.931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lA2SrrYXhlq",
        "outputId": "3159d89a-0fcb-443e-e136-e187adffc696"
      },
      "source": [
        "model.load_state_dict(torch.load('getoen-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, loss_fn)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.186 | Test PPL:  24.183 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCEI2cvbipi-"
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "    # print(sentence)\n",
        "\n",
        "    # sys.exit()\n",
        "\n",
        "    # Load german tokenizer\n",
        "    spacy_ger = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # print(tokens)\n",
        "\n",
        "    # sys.exit()\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "    tokens.insert(0, source.init_token)\n",
        "    tokens.append(source.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "    text_to_indices = [source.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        op,hidden = model.encoder(sentence_tensor)\n",
        "\n",
        "    outputs = [target.vocab.stoi[\"<sos>\"]]\n",
        "    \n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(previous_word, hidden, op)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == target.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [target.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    # remove start token\n",
        "    return \" \" .join(translated_sentence[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWkfeMGBsBG4",
        "outputId": "d33d4c79-6b83-4e0d-afe1-f490bd8a522e"
      },
      "source": [
        "for i in range(0,20):\n",
        "  t=vars(test_data.examples[i])\n",
        "  t1=t[\"src\"][::-1]\n",
        "\n",
        "  t2=\" \" .join(t[\"src\"])\n",
        "  print(\"german sentence:\",t2)\n",
        "  target1 =\" \".join(t[\"trg\"])\n",
        "  print(\"ground truth:\",target1)\n",
        "  translated_sentence = translate_sentence(\n",
        "        model,t2, source, target, device, max_length=50\n",
        "    )\n",
        "  print(\"tranlated sentence:\",translated_sentence[1:])\n",
        "  print(\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "german sentence: ein mann mit einem orangefarbenen hut , der etwas anstarrt .\n",
            "ground truth: a man in an orange hat starring at something .\n",
            "tranlated sentence:  man in an orange hat welding something . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein boston terrier läuft über saftig-grünes gras vor einem weißen zaun .\n",
            "ground truth: a boston terrier is running on lush green grass in front of a white fence .\n",
            "tranlated sentence:  golden dog runs running on grass grass in front of a white fence . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein mädchen in einem karateanzug bricht ein brett mit einem tritt .\n",
            "ground truth: a girl in karate uniform breaking a stick with a front kick .\n",
            "tranlated sentence:  girl in a karate uniform is a a a a a . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: fünf leute in winterjacken und mit helmen stehen im schnee mit schneemobilen im hintergrund .\n",
            "ground truth: five people wearing winter jackets and helmets stand in the snow , with snowmobiles in the background .\n",
            "tranlated sentence: ive people wearing life jackets and helmets standing in the background with with in the background . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: leute reparieren das dach eines hauses .\n",
            "ground truth: people are fixing the roof of a house .\n",
            "tranlated sentence: eople repair the roof roof of a house . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein hell gekleideter mann fotografiert eine gruppe von männern in dunklen anzügen und mit hüten , die um eine frau in einem trägerlosen kleid herum stehen .\n",
            "ground truth: a man in light colored clothing photographs a group of men wearing dark suits and hats standing around a woman dressed in a strapless gown .\n",
            "tranlated sentence:  man in a is a picture of men in camouflage and and hats , a woman in a flowered dress . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: eine gruppe von menschen steht vor einem iglu .\n",
            "ground truth: a group of people standing in front of an igloo .\n",
            "tranlated sentence:  group of people standing in an an art . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein junge in einem roten trikot versucht , die home base zu erreichen , während der catcher im blauen trikot versucht , ihn zu fangen .\n",
            "ground truth: a boy in a red uniform is attempting to avoid getting out at home plate , while the catcher in the blue uniform is attempting to catch him .\n",
            "tranlated sentence:  boy in a red jersey attempts to block the ball as he is in the blue tries to block the blue and tries to block him . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein typ arbeitet an einem gebäude .\n",
            "ground truth: a guy works on a building .\n",
            "tranlated sentence:  guy works on a building . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein mann in einer weste sitzt auf einem stuhl und hält magazine .\n",
            "ground truth: a man in a vest is sitting in a chair and holding magazines .\n",
            "tranlated sentence:  man in a vest is sitting on a stool holding holding up . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: eine mutter und ihr kleiner sohn genießen einen schönen tag im freien .\n",
            "ground truth: a mother and her young song enjoying a beautiful day outside .\n",
            "tranlated sentence:  mother and her son enjoying enjoying beautiful beautiful day day . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: männer , die volleyball spielen , wobei ein mann den ball nicht trifft , während seine hände immer noch in der luft sind .\n",
            "ground truth: men playing volleyball , with one player missing the ball but hands still in the air .\n",
            "tranlated sentence: en playing volleyball and one man is the the ball , his fingers in the air . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: eine frau , die in einer küche eine schale mit essen hält .\n",
            "ground truth: a woman holding a bowl of food in a kitchen .\n",
            "tranlated sentence:  woman holding a bowl in a kitchen . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein sitzender mann , der an einem tisch in seinem haus mit einem werkzeug arbeitet .\n",
            "ground truth: man sitting using tool at a table in his home .\n",
            "tranlated sentence:  man sitting at a table in a house with a tool . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: drei leute sitzen in einer höhle .\n",
            "ground truth: three people sit in a cave .\n",
            "tranlated sentence: hree people sit sitting in a cave . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: ein mädchen in einem jeanskleid läuft über einen erhöhten schwebebalken .\n",
            "ground truth: a girl in a jean dress is walking along a raised balance beam .\n",
            "tranlated sentence:  girl in a denim outfit is walking across an orange beam . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: eine blondine hält mit einem mann im sand händchen .\n",
            "ground truth: a blond holding hands with a guy in the sand .\n",
            "tranlated sentence:  woman is holding a man in the sand . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: eine frau in einem grauen pulli und mit einer schwarzen baseballmütze steht in einem geschäft in der schlange .\n",
            "ground truth: a woman in a gray sweater and black baseball cap is standing in line at a shop .\n",
            "tranlated sentence:  woman in a gray sweater and a black baseball cap stands in a store in a store . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: die person im gestreiften shirt klettert auf einen berg .\n",
            "ground truth: the person in the striped shirt is mountain climbing .\n",
            "tranlated sentence: he person in the striped shirt climbing climbing a mountain . <eos>\n",
            "\n",
            "\n",
            "\n",
            "german sentence: zwei männer tun so als seien sie statuen , während frauen ihnen zusehen .\n",
            "ground truth: two men pretend to be statutes while women look on .\n",
            "tranlated sentence: wo men are <unk> as <unk> while while while women watch . <eos>\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSOhyJ6sJW7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
